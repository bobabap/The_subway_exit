# 시각 장애인을(교통 약자) 위한 지하철 출구 및 비상구 찾기

## 프로젝트 배경

- 유튜브를 보다가 한 시각장애를 가진 유튜버의 고충을 보게되었다.
- 시각장애인 눈을 실명한 분들보다 색깔 정도를 구분 할 수 있거나 가까이서 봐야 글자를 어느정도 구분 할 수 있는 사람들이 대부분이라고 한다.
- 시각 장애인은 점자 블록 파손 및 잘못된 설치, 탑승 안내 점자 오류, 스크린 도어 미설치, 길거리 보행중 방해물, 표지판 색깔 혼동 등 많은 불편함을 느낀다.
- 시각장애인은 **지하철에 음성 안내를 들을 수 없는 경우 출구와, 비상구 찾기가 힘들다.**

## 프로젝트 목적

핸드폰 카메라를 이용해 시각장애인의 눈이 되어 지하철에서 **시각장애인용 편의시설의 노후화로 인한 불편함을 보안하고** 도움을 주는데 목적이있다.

## 프로젝트 진행 순서

1. yolov5 라이브러리 사용법 숙지
2. 비상구 표지판 사진 크롤링
3. 표지판 라벨링 후 train, validation set 나누기
4. pyyaml 라이브러리로 yolov5s.yaml을 class 개수 1개로 커스텀 저장
5. 80 epochs학습
6. 학습 완료된 [best.pt](http://best.pt) 저장
7. 영상, 사진 예측

> 라이브러리
> 
- YOLO v5
- yaml
- register_line_cell_magic

### 딥러닝 학습 사진 100장 결과

- 나가는 곳

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0b4a7dc6-9cd6-4bb8-a432-3c188558a4ac/Untitled.png)

![성능이 안 좋음](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6a337744-e66a-4b05-b671-165f9a334681/Untitled.png)

성능이 안 좋음

- 비상구

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/00328116-2f24-4a8a-a503-c622d0a1f23f/Untitled.png)

---

## 프로젝트의 한계, 느낀 점

1. 객체 탐지 모델을 만드려면 많은 양의 사진이 필요하다
2. 크롤링만으로 해결하지 못하는 경우 직접 찍어야하는 수고도 필요하다
3. 데이터의 중요성

## 프로젝트 모델 성능 개선

1. 구글에서 사진을 찾기에 한계가 있기 때문에 직접 찍은 사진이 필요하다.
2. 1000장 정도를 직접 찍고 라벨링을 한다.
3. 커스텀 yaml파일에서 클래스 개수 외에 파라미터 수정을 한다.

## 프로젝트 이상적인 지향 목표

1. 지하철 뿐만 아니라 길 안내, 장애물 위치 안내, 찾는 간판, 등 확장 활용 (길거리 보행자 데이터 셋이 있음)
2. 앱 사용시 간판 데이터 실시간 추가 수집하여 성능 개선
